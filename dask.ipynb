{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "united-jungle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T11:35:47.957587Z",
     "start_time": "2021-03-24T11:35:47.925310Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask_saturn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-1a45056b4f43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdask_saturn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSaturnCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dask_saturn'"
     ]
    }
   ],
   "source": [
    "from dask_ml.model_selection import HyperbandSearchCV\n",
    "from dask_ml.wrappers import ParallelPostFit\n",
    "from dask.distributed import Client\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from dask import dataframe as dd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import time\n",
    "from dask_saturn import SaturnCluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "occupational-silicon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T10:45:19.646932Z",
     "start_time": "2021-03-24T10:45:19.516943Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg = dd.read_csv('./data/possitive_case.csv')\n",
    "pos = dd.read_csv('./data/negative_case.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unable-revelation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T10:45:21.471997Z",
     "start_time": "2021-03-24T10:45:21.466839Z"
    }
   },
   "outputs": [],
   "source": [
    "neg_columns = ['Unnamed: 0','marketplace','star_rating','helpful_votes','total_votes','verified_purchase','review_headline','review_date','product_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "processed-liechtenstein",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T10:45:22.683021Z",
     "start_time": "2021-03-24T10:45:22.658818Z"
    }
   },
   "outputs": [],
   "source": [
    "neg_reviews_df = neg.drop(columns=neg_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "capable-publication",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T10:45:37.043413Z",
     "start_time": "2021-03-24T10:45:37.031044Z"
    }
   },
   "outputs": [],
   "source": [
    "pos['Status'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "latter-oregon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T10:45:53.427382Z",
     "start_time": "2021-03-24T10:45:53.400271Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_reviews_df = pos.drop(columns=neg_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "registered-treatment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T10:46:07.344905Z",
     "start_time": "2021-03-24T10:46:07.339417Z"
    }
   },
   "outputs": [],
   "source": [
    "join = [pos_reviews_df,neg_reviews_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "labeled-catering",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T10:49:52.359905Z",
     "start_time": "2021-03-24T10:49:52.320427Z"
    }
   },
   "outputs": [],
   "source": [
    "joined = pos_reviews_df.merge(neg_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "contained-workstation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T10:50:09.477748Z",
     "start_time": "2021-03-24T10:50:09.463902Z"
    }
   },
   "outputs": [],
   "source": [
    "joined = joined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "behind-department",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T11:00:53.429262Z",
     "start_time": "2021-03-24T11:00:36.531611Z"
    }
   },
   "outputs": [],
   "source": [
    "text, status = list(joined['review_body']), list(joined['Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "statewide-thursday",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T11:00:59.741621Z",
     "start_time": "2021-03-24T11:00:59.703703Z"
    }
   },
   "outputs": [],
   "source": [
    "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
    "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
    "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
    "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
    "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
    "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
    "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n",
    "\n",
    "Url_Pattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "User_Pattern = '@[^\\s]+'\n",
    "Alph_Num_Pattern = \"[^a-zA-Z0-9]\"\n",
    "Repeat_Pattern = r\"(.)\\1\\1+\"\n",
    "Replace_Pattern = r\"\\1\\1\"\n",
    "\n",
    "def process_words(text):\n",
    "    processed_text = []\n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    for review in text:\n",
    "        review = re.sub(Alph_Num_Pattern, ' ', review)\n",
    "        review = review.lower()\n",
    "        review = re.sub(Url_Pattern, 'Url', review)\n",
    "        for emoji in emojis.keys():\n",
    "            review = review.replace(emoji, emojis[emoji])\n",
    "        review = re.sub(User_Pattern, 'User', review)\n",
    "        review = re.sub(Repeat_Pattern, Replace_Pattern, review)\n",
    "        review_words = ''\n",
    "        for word in review.split():\n",
    "            if len(word)>1:\n",
    "                word = wordLemm.lemmatize(word)\n",
    "                review_words += (word+' ')\n",
    "                \n",
    "        processed_text.append(review_words)\n",
    "    return processed_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "historical-therapist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T11:02:48.064217Z",
     "start_time": "2021-03-24T11:01:46.347647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n",
      "Time Taken: 62 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "processedtext = process_words(text)\n",
    "print(f'Text Preprocessing complete.')\n",
    "print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "differential-humanitarian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T11:03:30.050848Z",
     "start_time": "2021-03-24T11:03:28.917008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split done.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text, status,\n",
    "                                                    test_size = 0.2, random_state = 0,shuffle=True)\n",
    "print(f'Data Split done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "higher-stream",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T11:03:45.948497Z",
     "start_time": "2021-03-24T11:03:33.861572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectoriser fitted.\n",
      "No. of feature_words:  1714\n"
     ]
    }
   ],
   "source": [
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=400000)\n",
    "X_train = vectoriser.fit_transform(X_train)\n",
    "X_test = vectoriser.transform(X_test)\n",
    "print(f'Vectoriser fitted.')\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "parallel-duplicate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T11:03:52.357608Z",
     "start_time": "2021-03-24T11:03:52.336642Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_Evaluate(model):\n",
    "    \n",
    "    # Predict values for Test dataset\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Print the evaluation metrics for the dataset.\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Compute and plot the Confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    categories  = ['Negative','Positive']\n",
    "    group_names = ['True Neg','False Pos', 'False Neg','True Pos']\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_names,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "    sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n",
    "                xticklabels = categories, yticklabels = categories)\n",
    "\n",
    "    plt.xlabel(\"Predicted values\", fontdict = {'size':14}, labelpad = 10)\n",
    "    plt.ylabel(\"Actual values\"   , fontdict = {'size':14}, labelpad = 10)\n",
    "    plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "heard-guide",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T11:03:53.755359Z",
     "start_time": "2021-03-24T11:03:53.501143Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b104a22f7702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLogModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLogModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_Evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvinarellano/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[1;32m   1375\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "LogModel = LogisticRegression()\n",
    "LogModel.fit(X_train, y_train)\n",
    "model_Evaluate(LogModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afraid-budapest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T12:10:47.416153Z",
     "start_time": "2021-03-24T12:10:45.180565Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelvinarellano/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 64347 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    }
   ],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "raised-prior",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T12:34:59.646368Z",
     "start_time": "2021-03-24T12:34:59.640741Z"
    }
   },
   "outputs": [],
   "source": [
    "LogParams = {\n",
    "    'C':[1.0,10.0,100.0,1000.0],\n",
    "    'max_iter':[1,10,100,500], \n",
    "    'solver':['lbfgs','liblinear','sag','saga'], \n",
    "    'penalty':['l2','elasticnet']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-copper",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-24T12:35:01.422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    }
   ],
   "source": [
    "with joblib.parallel_backend('dask'):\n",
    "    grid_log = GridSearchCV(estimator=LogisticRegression(),\n",
    "                 param_grid=LogParams,\n",
    "                 scoring='accuracy',\n",
    "                 verbose=1,\n",
    "                 n_jobs=-1)\n",
    "    results_grid_Log = grid_log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-spice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_Log = GridSearchCV(estimator=LogisticRegression(),\n",
    "                    param_grid=LogParams,\n",
    "                    scoring='accuracy',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "result_grid_SVC = grid_Log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator, param_grid, verbose=2, cv=2)\n",
    "grid_search.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
